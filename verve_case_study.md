# Verve Group data science case study - Louis Lippmann

1. **Imagine that you were asked to use this dataset to build a classification model, with `gender` as the target. Look at the information we have given you and identify 3-5 potential problems you can see with the provided dataset that might make building a classification model difficult.**
   - The dataset is imbalanced, meaning the target variable "gender" has more observations for the class "male" than in the class "female". Models trained on unbalanced datasets often have poor results when they have to generalize as they might simply predict the majority class in all cases.
   - Many machine learning models require their input to be numerical. The data contained within the column "device_name" are hard to transform into numerical data, as they do not represent categories that could be transformed with one hot encoding. However, the column may contain a first name, which could acts a very important feature to infer the gender of a person. In order to use the name effectively as a feature, a number of data cleaning operations would be necessary. Nevertheless, there is another problem with this column. About 60% of the values are missing, 
   - Another problem might be the number of samples for certain classes of app and ad categories with classes that occur very rarely.  A large number of categorical feature adds a large number of additional features in the encoding.
   - Finally, there are only 18 samples of the feature if the ad was clicked. Together with the imbalance of the dataset, this may lead to overfitting. Assuming that the majority of clicks on ads are male, the model may learn that when a person clicks on ads, that person is a male. 
2. **Describe briefly how you would find the features that are likely to be the most important for your model.**
   - In order to find the best features for the model there exist various approaches. One way could be to drop variables that have a high percentage of missing values, like the "device_name" with almost 60% missing values. Next, one could observe pairwise correlations and drop one of the variables that correlate with each other to reduce the dimensionality. Furthermore values with very low variation could be dropped. Finally variables that correlate low with the target could be dropped. Another approach would be to try forward or backward feature selection. 
3. **Identify which model you would try first, and at least one advantage and disadvantage of this choice.**
   - With a Spot Check, one can quickly get an overview of which model seems to be particularly well suited for the data. However, to start I would choose a rather simple model like Logistic Regression. It is fast to implement and easy to interpret. The major drawback of Logistic Regression is the assumption of linearity between the dependent variable and the independent variables.

